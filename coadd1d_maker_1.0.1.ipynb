{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway = '/Volumes/Jiamu2/Pypeit1.3.0/2020feb26_pypeit_red/hgc1a_results/1.3.2_test/keck_deimos_A/det37_new'\n",
    "possible_paths = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(pathway)) for f in fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec1d_files = []\n",
    "spec1d_dict = {}\n",
    "for file in possible_paths:\n",
    "    if ('spec1d_' in file) and ('.txt' in file):\n",
    "        spec1d_files.append(file)\n",
    "        last_slash_ind = file.rfind('/')\n",
    "        path = file[:last_slash_ind+1]\n",
    "        if path not in spec1d_dict:\n",
    "            spec1d_dict[path] = []\n",
    "        spec1d_dict[path].append(file[last_slash_ind+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Volumes/Jiamu2/Pypeit1.3.0/2020feb26_pypeit_red/hgc1a_results/1.3.2_test/keck_deimos_A/det37_new/Science/spec1d_d0226_0061-hgc1a_DEIMOS_2020Feb26T055522.915.txt',\n",
       " '/Volumes/Jiamu2/Pypeit1.3.0/2020feb26_pypeit_red/hgc1a_results/1.3.2_test/keck_deimos_A/det37_new/Science/spec1d_d0226_0062-hgc1a_DEIMOS_2020Feb26T061443.181.txt',\n",
       " '/Volumes/Jiamu2/Pypeit1.3.0/2020feb26_pypeit_red/hgc1a_results/1.3.2_test/keck_deimos_A/det37_new/Science/spec1d_d0226_0063-hgc1a_DEIMOS_2020Feb26T063353.251.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec1d_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G_65703339124992' '780896.0' '779296.0' 'G_65741993950848'\n",
      " 'G_66631052293120' 'G_66631052064768' 'G_66631052064256'\n",
      " 'G_66699771952128' '789063.0' '793082.0' 'G_66596692325376'\n",
      " 'G_66596693805440' '788401.0' 'G_65016144356864' '806552.0'\n",
      " 'G_64844345661312' 'G_65084863834752' '789605.0' 'G_66871570238592'\n",
      " 'G_66768491017856' 'G_65703339124992' '780896.0' 'G_65741993950848'\n",
      " 'G_66631052293120' 'G_66631052064768' 'G_66631052064256'\n",
      " 'G_66699771952128' '789063.0' '793082.0' 'G_66596692325376'\n",
      " 'G_66596693805440' 'G_65016144356864' 'G_64844345661312' 'SERENDIP'\n",
      " '793902.0' 'SERENDIP' 'G_65084863834752' 'G_66871570238592'\n",
      " 'G_66768491017856']\n"
     ]
    }
   ],
   "source": [
    "tol_dict = {'slit':20,'spat_pixpos':20,'s2n':100} \n",
    "snr_thresh = 0.1\n",
    "\n",
    "for path in spec1d_dict: \n",
    "    spec1d_texts = spec1d_dict[path]\n",
    "    spec1d_contents = {}\n",
    "    for file in spec1d_texts: #loop over the different observations of the same mask on the same date\n",
    "        spec1d_contents[file] = {}\n",
    "        with open(f'{path}{file}','r') as f: #read each spec1d.txt file\n",
    "            lines = f.readlines()\n",
    "        labels = lines[0].strip().split('|') #get the labels\n",
    "        for j in range(len(labels)):\n",
    "            labels[j] = labels[j].strip()\n",
    "        while '' in labels:\n",
    "            labels.remove('')\n",
    "        labels.append('det_num')\n",
    "        data = []\n",
    "        for line in lines[1:]: #get the data\n",
    "            line = line.strip().split('|')\n",
    "            while '' in line:\n",
    "                line.remove('')\n",
    "            for j in range(len(line)):\n",
    "                line[j] = line[j].strip()\n",
    "                if '-DET' in line[j]:\n",
    "                    det_num = line[j].split('-')[-1]\n",
    "                try:\n",
    "                    line[j] = float(line[j])\n",
    "                except:\n",
    "                    pass\n",
    "            line.append(det_num)\n",
    "            data.append(line)\n",
    "        #save the labels and data into a dictionary\n",
    "        for j in range(len(labels)):\n",
    "            if labels[j] not in spec1d_contents[file]:\n",
    "                spec1d_contents[file][labels[j]] = []\n",
    "            for row in data:\n",
    "                spec1d_contents[file][labels[j]].append(row[j])\n",
    "            spec1d_contents[file][labels[j]] = np.array(spec1d_contents[file][labels[j]])\n",
    "    internal_matches = {} #find matches within each spec1d text file\n",
    "    filenames = spec1d_contents.keys()\n",
    "    print(spec1d_contents[file]['objname'])\n",
    "    for j,file in enumerate(filenames):\n",
    "        first_det = -1\n",
    "        internal_matches[file] = []\n",
    "        for k in range(len(spec1d_contents[file]['name'])):\n",
    "            if first_det == -1:\n",
    "                first_det = spec1d_contents[file]['det_num'][k]\n",
    "            if spec1d_contents[file]['s2n'][k] < snr_thresh:\n",
    "                continue\n",
    "            match_params = []\n",
    "            current_matches = np.array(internal_matches[file])\n",
    "\n",
    "            for kk in range(len(spec1d_contents[file]['name'])):\n",
    "#                 if len(current_matches) > 0:\n",
    "#                     if (spec1d_contents[file]['det_num'][kk] != first_det) and \\\n",
    "#                        (spec1d_contents[file]['name'] in current_matches[:,1]):\n",
    "#                         continue\n",
    "                if k == kk:\n",
    "                    continue\n",
    "                elif spec1d_contents[file]['s2n'][kk] < snr_thresh:\n",
    "                    continue\n",
    "                elif spec1d_contents[file]['det_num'][k] == spec1d_contents[file]['det_num'][kk]:\n",
    "                    continue\n",
    "                elif spec1d_contents[file]['objname'][k] != spec1d_contents[file]['objname'][kk]:\n",
    "                    continue\n",
    "                else:\n",
    "                    match_params.append((k,kk,\n",
    "                                         np.abs(spec1d_contents[file]['slit'][k]-spec1d_contents[file]['slit'][kk]),\n",
    "                                         np.abs(spec1d_contents[file]['spat_pixpos'][k]-spec1d_contents[file]['spat_pixpos'][kk]),\n",
    "                                         np.abs(spec1d_contents[file]['s2n'][k]-spec1d_contents[file]['s2n'][kk]),\n",
    "                                        ))\n",
    "            match_params = np.array(match_params)\n",
    "            if len(match_params) == 0:\n",
    "                continue\n",
    "            elif np.min(match_params[:,2]) > tol_dict['slit']:\n",
    "                continue\n",
    "            good_matches = (match_params[:,2] <= tol_dict['slit']) &\\\n",
    "                           (match_params[:,3] <= tol_dict['spat_pixpos']) &\\\n",
    "                           (match_params[:,4] <= tol_dict['s2n'])\n",
    "            if np.sum(good_matches) == 0:\n",
    "                continue\n",
    "            elif np.sum(good_matches) > 1: ####NEED TO WRITE THIS SECTION!\n",
    "                slit_diffs = match_params[good_matches][:,2]\n",
    "                spat_diffs = match_params[good_matches][:,3]\n",
    "                s2n_diffs = match_params[good_matches][:,4]\n",
    "                if np.all(slit_diffs == slit_diffs[0]): #then they share slit numbers\n",
    "                    if np.all(spat_diffs == spat_diffs[0]):\n",
    "                        if np.all(s2n_diffs == s2n_diffs[0]):\n",
    "                            print(match_params[good_matches])\n",
    "                            raise ValueError('ERROR: All metrics match, so no pair was found.')\n",
    "                        else:\n",
    "                            best_match = np.argmin(s2n_diffs)\n",
    "                    else:\n",
    "                        best_match = np.argmin(spat_diffs)\n",
    "                else:\n",
    "                    best_match = np.argmin(slit_diffs)\n",
    "                slice_vals = match_params[good_matches][best_match]\n",
    "                inds = np.array([slice_vals[0],slice_vals[1]]).astype(int)\n",
    "            else: #one match\n",
    "                slice_vals = match_params[good_matches][0]\n",
    "                inds = np.array([slice_vals[0],slice_vals[1]]).astype(int)\n",
    "            det_nums = spec1d_contents[file]['det_num'][inds]\n",
    "            det1,det2 = int(det_nums[0][3:]),int(det_nums[1][3:])\n",
    "            if det1 > det2:\n",
    "                inds = np.array([inds[1],inds[0]])\n",
    "            current_pair = spec1d_contents[file]['name'][inds]\n",
    "            already_paired = False\n",
    "            for row in current_matches:\n",
    "                if (current_pair[0] == row[0]) and (current_pair[1] == row[1]):\n",
    "                    already_paired = True\n",
    "                    continue\n",
    "            if not already_paired:\n",
    "                internal_matches[file].append(current_pair)\n",
    "        internal_matches[file] = np.array(internal_matches[file])\n",
    "        \n",
    "    external_matches = [] #find matches between spec1d text files\n",
    "    for j,file in enumerate(filenames):\n",
    "        first_det = -1\n",
    "        for k in range(len(spec1d_contents[file]['name'])):\n",
    "            if first_det == -1:\n",
    "                first_det = spec1d_contents[file]['det_num'][k]\n",
    "            if spec1d_contents[file]['s2n'][k] < snr_thresh:\n",
    "                continue\n",
    "            \n",
    "            for file2 in filenames:\n",
    "                match_params = []\n",
    "                current_matches = np.copy(external_matches)\n",
    "                if file == file2:\n",
    "                    continue\n",
    "                for kk in range(len(spec1d_contents[file2]['name'])):\n",
    "    #                 if len(current_matches) > 0:\n",
    "    #                     if (spec1d_contents[file]['det_num'][kk] != first_det) and \\\n",
    "    #                        (spec1d_contents[file]['name'] in current_matches[:,1]):\n",
    "    #                         continue\n",
    "                    if k == kk:\n",
    "                        continue\n",
    "                    elif spec1d_contents[file2]['s2n'][kk] < snr_thresh:\n",
    "                        continue\n",
    "                    elif spec1d_contents[file]['det_num'][k] != spec1d_contents[file2]['det_num'][kk]:\n",
    "                        continue\n",
    "                    else:\n",
    "                        match_params.append((k,kk,\n",
    "                                             np.abs(spec1d_contents[file]['slit'][k]-spec1d_contents[file2]['slit'][kk]),\n",
    "                                             np.abs(spec1d_contents[file]['spat_pixpos'][k]-spec1d_contents[file2]['spat_pixpos'][kk]),\n",
    "                                             np.abs(spec1d_contents[file]['s2n'][k]-spec1d_contents[file2]['s2n'][kk]),\n",
    "                                             ))\n",
    "                match_params = np.array(match_params)\n",
    "                if len(match_params) == 0:\n",
    "                    continue\n",
    "                elif np.min(match_params[:,2]) > tol_dict['slit']:\n",
    "                    continue\n",
    "                good_matches = (match_params[:,2] <= tol_dict['slit']) &\\\n",
    "                               (match_params[:,3] <= tol_dict['spat_pixpos']) &\\\n",
    "                               (match_params[:,4] <= tol_dict['s2n'])\n",
    "                if np.sum(good_matches) == 0:\n",
    "                    continue\n",
    "                elif np.sum(good_matches) > 1: ####NEED TO WRITE THIS SECTION!\n",
    "                    slit_diffs = match_params[good_matches][:,2]\n",
    "                    spat_diffs = match_params[good_matches][:,3]\n",
    "                    s2n_diffs = match_params[good_matches][:,4]\n",
    "                    if np.all(slit_diffs == slit_diffs[0]): #then they share slit numbers\n",
    "                        if np.all(spat_diffs == spat_diffs[0]):\n",
    "                            if np.all(s2n_diffs == s2n_diffs[0]):\n",
    "                                print(match_params[good_matches])\n",
    "                                raise ValueError('ERROR: All metrics match, so no pair was found.')\n",
    "                            else:\n",
    "                                best_match = np.argmin(s2n_diffs)\n",
    "                        else:\n",
    "                            best_match = np.argmin(spat_diffs)\n",
    "                    else:\n",
    "                        best_match = np.argmin(slit_diffs)\n",
    "                    slice_vals = match_params[good_matches][best_match]\n",
    "                else: #one match\n",
    "                    slice_vals = match_params[good_matches][0]\n",
    "                inds = np.array([slice_vals[0],slice_vals[1]]).astype(int)\n",
    "                current_pair = [file+'/'+spec1d_contents[file]['name'][inds[0]],\n",
    "                                file2+'/'+spec1d_contents[file2]['name'][inds[1]]]\n",
    "                already_paired = False\n",
    "                for row in current_matches:\n",
    "                    if (current_pair[0] == row[0]) and (current_pair[1] == row[1]):\n",
    "                        already_paired = True\n",
    "                        continue\n",
    "                    elif (current_pair[1] == row[0]) and (current_pair[0] == row[1]):\n",
    "                        already_paired = True\n",
    "                        continue\n",
    "                if not already_paired:\n",
    "                    external_matches.append(current_pair)\n",
    "    external_matches = np.array(external_matches)\n",
    "    final_matches = {}\n",
    "    added_matches = []\n",
    "    for pair in external_matches:\n",
    "        entry1,entry2 = pair\n",
    "        f1,f2 = entry1.split('/')[0],entry1.split('/')[1]\n",
    "        spat1,spat2 = entry1.split('-SLIT')[0][-4:],entry2.split('-SLIT')[0][-4:]\n",
    "        all_matches = [entry1,entry2]\n",
    "        for pair2 in external_matches:\n",
    "            p2_entry1,p2_entry2 = pair2\n",
    "            if (entry1 == p2_entry1) and (entry2 == p2_entry2):\n",
    "                continue\n",
    "            elif (entry2 == p2_entry1) and (entry1 == p2_entry2):\n",
    "                continue\n",
    "            elif ((entry1 != p2_entry1) and (entry2 != p2_entry2)) and \\\n",
    "                 ((entry2 != p2_entry1) and (entry1 != p2_entry2)):\n",
    "                continue\n",
    "            for entry in pair2:\n",
    "                if entry not in all_matches:\n",
    "                    all_matches.append(entry)\n",
    "        not_already_added = False\n",
    "        for entry in all_matches:\n",
    "            if entry not in added_matches:\n",
    "                not_already_added = True\n",
    "        n_current_matches = len(all_matches)\n",
    "        for ind in range(n_current_matches):\n",
    "            entry = all_matches[ind]\n",
    "            f,name = entry.split('/')\n",
    "            poss_int_matches = internal_matches[f]\n",
    "            #print(poss_int_matches[0])\n",
    "            for pair2 in poss_int_matches:\n",
    "                if (name == pair2[0]):\n",
    "                    all_matches.append(f+'/'+pair2[1])\n",
    "                    break\n",
    "                elif (name == pair2[1]):\n",
    "                    all_matches.append(f+'/'+pair2[0])\n",
    "                    break\n",
    "        \n",
    "        not_already_added = False\n",
    "        spat_vals = []\n",
    "        for entry in all_matches:\n",
    "            if entry not in added_matches:\n",
    "                not_already_added = True\n",
    "            spat_vals.append(int(entry.split('SPAT')[1][:4]))\n",
    "        ave_spat = '%04d'%int(round(np.average(spat_vals)))\n",
    "        if not_already_added:\n",
    "            if ave_spat in final_matches:\n",
    "                print(f'\\n\\nConflict with SPAT{ave_spat}')\n",
    "                print('Already in dict:')\n",
    "                for line in final_matches[ave_spat]:\n",
    "                    print(line)\n",
    "                print('New proposal:')\n",
    "                for line in all_matches:\n",
    "                    print(line)\n",
    "                if len(final_matches[ave_spat]) < len(all_matches):\n",
    "                    final_matches[ave_spat] = all_matches\n",
    "            else:\n",
    "                final_matches[ave_spat] = all_matches\n",
    "            added_matches.extend(final_matches[ave_spat])\n",
    "#             if len(all_matches) not in [6]:\n",
    "#                 print(all_matches,len(all_matches))\n",
    "#                 for line in all_matches:\n",
    "#                     print(line)\n",
    "    outpath = f'{path}coadd1d_results/'\n",
    "    #if not os.path.isdir(outpath):\n",
    "        #os.makedirs(outpath)\n",
    "    #for spat in final_matches:\n",
    "        #with open(f'{outpath}SPAT{spat}_coadd1d_instruct.txt','w') as f:\n",
    "            #f.write(\"# User-defined coadding parameters\\n\")\n",
    "            #f.write(\"[coadd1d]\\n\")\n",
    "            #f.write(f\"    coaddfile = 'SPAT{spat}_coadd1d.fits'\\n\")\n",
    "            #f.write(\"    flux_value = False\\n\\n\")\n",
    "            #f.write(\"# Read in the data\\n\")\n",
    "            #f.write(\"coadd1d read\\n\")\n",
    "            ###LOOP OVER THE FILES!\n",
    "            #for file in final_matches[spat]:\n",
    "                #filepath,entry = file.split('/')\n",
    "                #spec1d_filepath = filepath.split('.txt')[0]+'.fits'\n",
    "                #f.write(f\"    ../{spec1d_filepath} {entry}\\n\")\n",
    "            #f.write(\"coadd1d end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
